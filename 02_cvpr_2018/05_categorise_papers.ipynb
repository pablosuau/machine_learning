{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablo/anaconda3/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sucessfully running a clutering pipeline on the CVPR 2018 papers data, the aim of this notebook is to manually assign a label to each cluster to identify the topic of the papers in each cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = pickle.load(open('models/kmeans.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_papers():\n",
    "    papers = sorted(glob.glob('data/*.txt'))\n",
    "    df = pd.DataFrame(columns=['paper', 'len'], index=range(len(papers)))\n",
    "\n",
    "    i = 0\n",
    "    for paper in papers:\n",
    "        with open(paper, 'r') as f:\n",
    "            text = f.readlines()\n",
    "        df.iloc[i, :] = [paper, len(text[0])]\n",
    "        i = i + 1\n",
    "    df = df[~(df['len'] < 5000) & ~(df['len'] > 80000)]\n",
    "    \n",
    "    return df\n",
    "df = get_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_files = [p\n",
    "                .replace('data/', '')\n",
    "                .replace('.txt', '.pdf')\n",
    "                for p in df.paper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the paper names\n",
    "\n",
    "We parse the page again to get the complete paper names from the pdf file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the page\n",
    "response = requests.get(\"http://openaccess.thecvf.com/CVPR2018.py\")\n",
    "page_html = response.text\n",
    "soup = BeautifulSoup(page_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Embodied Question Answering</td>\n",
       "      <td>Das_Embodied_Question_Answering_CVPR_2018_pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Learning by Asking Questions</td>\n",
       "      <td>Misra_Learning_by_Asking_CVPR_2018_paper.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finding Tiny Faces in the Wild With Generative...</td>\n",
       "      <td>Bai_Finding_Tiny_Faces_CVPR_2018_paper.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learning Face Age Progression: A Pyramid Archi...</td>\n",
       "      <td>Yang_Learning_Face_Age_CVPR_2018_paper.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PairedCycleGAN: Asymmetric Style Transfer for ...</td>\n",
       "      <td>Chang_PairedCycleGAN_Asymmetric_Style_CVPR_201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                        Embodied Question Answering   \n",
       "1                       Learning by Asking Questions   \n",
       "2  Finding Tiny Faces in the Wild With Generative...   \n",
       "3  Learning Face Age Progression: A Pyramid Archi...   \n",
       "4  PairedCycleGAN: Asymmetric Style Transfer for ...   \n",
       "\n",
       "                                                 pdf  \n",
       "0  Das_Embodied_Question_Answering_CVPR_2018_pape...  \n",
       "1       Misra_Learning_by_Asking_CVPR_2018_paper.pdf  \n",
       "2         Bai_Finding_Tiny_Faces_CVPR_2018_paper.pdf  \n",
       "3         Yang_Learning_Face_Age_CVPR_2018_paper.pdf  \n",
       "4  Chang_PairedCycleGAN_Asymmetric_Style_CVPR_201...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([], columns=['name', 'pdf'])\n",
    "\n",
    "dl_tag = soup.find_all('dl')[0]\n",
    "dt_tag = dl_tag.find_all('dt')\n",
    "dd_tag = dl_tag.findChildren('dd', recursive=False)\n",
    "for i in range(len(dt_tag)):\n",
    "    dt = dt_tag[i]\n",
    "    dd = dd_tag[i*2 + 1]\n",
    "    \n",
    "    name = dt.text\n",
    "    pdf = dd.findChildren('a')[0]['href'].replace('content_cvpr_2018/papers/','')\n",
    "    \n",
    "    df.loc[i] = [name, pdf]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>A High-Quality Denoising Dataset for Smartphon...</td>\n",
       "      <td>Abdelhamed_A_High-Quality_Denoising_CVPR_2018_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>When Will You Do What? - Anticipating Temporal...</td>\n",
       "      <td>Abu_Farha_When_Will_You_CVPR_2018_paper.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Efficient Interactive Annotation of Segmentati...</td>\n",
       "      <td>Acuna_Efficient_Interactive_Annotation_CVPR_20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Don't Just Assume; Look and Answer: Overcoming...</td>\n",
       "      <td>Agrawal_Dont_Just_Assume_CVPR_2018_paper.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Image Collection Pop-Up: 3D Reconstruction and...</td>\n",
       "      <td>Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "174  A High-Quality Denoising Dataset for Smartphon...   \n",
       "552  When Will You Do What? - Anticipating Temporal...   \n",
       "88   Efficient Interactive Annotation of Segmentati...   \n",
       "514  Don't Just Assume; Look and Answer: Overcoming...   \n",
       "268  Image Collection Pop-Up: 3D Reconstruction and...   \n",
       "\n",
       "                                                   pdf  \n",
       "174  Abdelhamed_A_High-Quality_Denoising_CVPR_2018_...  \n",
       "552        Abu_Farha_When_Will_You_CVPR_2018_paper.pdf  \n",
       "88   Acuna_Efficient_Interactive_Annotation_CVPR_20...  \n",
       "514       Agrawal_Dont_Just_Assume_CVPR_2018_paper.pdf  \n",
       "268  Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.pdf  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out the discarded pdf files\n",
    "df = df[df.pdf.isin(paper_files)]\n",
    "df = df.sort_values(by='pdf')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pdf</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>A High-Quality Denoising Dataset for Smartphon...</td>\n",
       "      <td>Abdelhamed_A_High-Quality_Denoising_CVPR_2018_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>When Will You Do What? - Anticipating Temporal...</td>\n",
       "      <td>Abu_Farha_When_Will_You_CVPR_2018_paper.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Efficient Interactive Annotation of Segmentati...</td>\n",
       "      <td>Acuna_Efficient_Interactive_Annotation_CVPR_20...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Don't Just Assume; Look and Answer: Overcoming...</td>\n",
       "      <td>Agrawal_Dont_Just_Assume_CVPR_2018_paper.pdf</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Image Collection Pop-Up: 3D Reconstruction and...</td>\n",
       "      <td>Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.pdf</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "174  A High-Quality Denoising Dataset for Smartphon...   \n",
       "552  When Will You Do What? - Anticipating Temporal...   \n",
       "88   Efficient Interactive Annotation of Segmentati...   \n",
       "514  Don't Just Assume; Look and Answer: Overcoming...   \n",
       "268  Image Collection Pop-Up: 3D Reconstruction and...   \n",
       "\n",
       "                                                   pdf  cluster  \n",
       "174  Abdelhamed_A_High-Quality_Denoising_CVPR_2018_...        1  \n",
       "552        Abu_Farha_When_Will_You_CVPR_2018_paper.pdf       13  \n",
       "88   Acuna_Efficient_Interactive_Annotation_CVPR_20...        3  \n",
       "514       Agrawal_Dont_Just_Assume_CVPR_2018_paper.pdf       16  \n",
       "268  Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.pdf       20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'] = kmeans.labels_\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "25    12\n",
       "24    12\n",
       "22    16\n",
       "18    17\n",
       "7     22\n",
       "4     24\n",
       "11    25\n",
       "21    27\n",
       "2     29\n",
       "16    30\n",
       "8     31\n",
       "20    32\n",
       "5     34\n",
       "19    38\n",
       "23    44\n",
       "6     46\n",
       "15    47\n",
       "9     47\n",
       "10    48\n",
       "0     49\n",
       "14    49\n",
       "1     51\n",
       "12    51\n",
       "13    60\n",
       "17    62\n",
       "3     63\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_size = df.groupby('cluster').count()['name'].sort_values()\n",
    "cluster_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to display the papers in each cluster in order of cluster size.\n",
    "\n",
    "The list of cluster labels below was manually created after inspecting the list of papers two cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = {\n",
    "    25: 'Generative Adversarial Networks (GAN)',\n",
    "    24: 'Stereo',\n",
    "    22: 'Face detection/classification',\n",
    "    18: 'Visual saliency and gaze detection',\n",
    "    7: '3D objects',\n",
    "    4: 'Text detection/recognition',\n",
    "    11: 'Object recognition from very few examples',\n",
    "    21: 'Tracking',\n",
    "    2: 'Self-Localisation and Mapping (SLAM) and 3D reconstruction',\n",
    "    16: 'Visual questions answering',\n",
    "    8: 'Re-identification',\n",
    "    20: '3D reconstruction',\n",
    "    5: 'Transfer learning, domain adaptation and adversarial networks',\n",
    "    19: 'Lighting models',\n",
    "    23: 'Point clouds correspondences and matching',\n",
    "    6: 'Face detection/recognition',\n",
    "    15: 'Pose estimation',\n",
    "    9: 'Image/video captioning, object detection',\n",
    "    10: 'Generative Adversarial Networks (GAN)',\n",
    "    0: 'Object detection, video/object segmentation',\n",
    "    14: 'Image/points registration, visual features',\n",
    "    1: 'Image processing',\n",
    "    12: 'Deep learning',\n",
    "    13: 'Temporal representation/prediction',\n",
    "    17: 'Neural networks',\n",
    "    3: 'Object localisation/detection'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER 25: Generative Adversarial Networks (GAN)\n",
      "\n",
      "  Multi-Content GAN for Few-Shot Font Style Transfer\n",
      "  PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup\n",
      "  CartoonGAN: Generative Adversarial Networks for Photo Cartoonization\n",
      "  Disentangling Structure and Aesthetics for Style-Aware Image Completion\n",
      "  Arbitrary Style Transfer With Deep Feature Reshuffle\n",
      "  Creating Capsule Wardrobes From Fashion Images\n",
      "  Multi-Task Adversarial Network for Disentangled Feature Learning\n",
      "  A Common Framework for Interactive Texture Transfer\n",
      "  Neural Style Transfer via Meta Networks\n",
      "  Avatar-Net: Multi-Scale Zero-Shot Style Transfer by Feature Decoration\n",
      "  TextureGAN: Controlling Deep Image Synthesis With Texture Patches\n",
      "  Separating Style and Content for Generalized Style Transfer\n",
      "==============\n",
      "\n",
      "CLUSTER 24: Stereo\n",
      "\n",
      "  A Low Power, High Throughput, Fully Event-Based Stereo System\n",
      "  CBMV: A Coalesced Bidirectional Matching Volume for Disparity Estimation\n",
      "  Pyramid Stereo Matching Network\n",
      "  Stereoscopic Neural Style Transfer\n",
      "  DeepMVS: Learning Multi-View Stereopsis\n",
      "  Enhancing the Spatial Resolution of Stereo Images Using a Parallax Prior\n",
      "  Left-Right Comparative Recurrent Model for Stereo Matching\n",
      "  Learning for Disparity Estimation Through Feature Constancy\n",
      "  Single View Stereo Matching\n",
      "  Zoom and Learn: Generalizing Deep Stereo Matching to Novel Domains\n",
      "  Trust Your Model: Light Field Depth Estimation With Inline Occlusion Handling\n",
      "  Deep Material-Aware Cross-Spectral Stereo Matching\n",
      "==============\n",
      "\n",
      "CLUSTER 22: Face detection/classification\n",
      "\n",
      "  Partially Shared Multi-Task Convolutional Neural Network With Local Constraint for Face Attribute Learning\n",
      "  Deep Diffeomorphic Transformer Networks\n",
      "  Optimizing Filter Size in Convolutional Neural Networks for Facial Action Unit Recognition\n",
      "  Learning Structure and Strength of CNN Filters for Small Sample Size Training\n",
      "  OLÃ: Orthogonal Low-Rank Embedding - A Plug and Play Geometric Loss for Deep Learning\n",
      "  Deep Cost-Sensitive and Order-Preserving Feature Learning for Cross-Population Age Estimation\n",
      "  Deep Density Clustering of Unconstrained Faces\n",
      "  Mean-Variance Loss for Deep Age Estimation From a Face\n",
      "  Weakly Supervised Facial Action Unit Recognition Through Adversarial Training\n",
      "  Deep Regression Forests for Age Estimation\n",
      "  Bilateral Ordinal Relevance Multi-Instance Regression for Facial Action Unit Intensity Estimation\n",
      "  Classifier Learning With Prior Probabilities for Facial Action Unit Recognition\n",
      "  Weakly-Supervised Deep Convolutional Neural Network Learning for Facial Action Unit Intensity Estimation\n",
      "  Learning Facial Action Units From Web Images With Scalable Weakly Supervised Clustering\n",
      "  Ring Loss: Convex Feature Normalization for Face Recognition\n",
      "  LDMNet: Low Dimensional Manifold Regularized Neural Networks\n",
      "==============\n",
      "\n",
      "CLUSTER 18: Visual saliency and gaze detection\n",
      "\n",
      "  Progressively Complementarity-Aware Fusion Network for RGB-D Salient Object Detection\n",
      "  Cube Padding for Weakly-Supervised Saliency Prediction in 360Â° Videos\n",
      "  Emotional Attention: A Study of Image Sentiment and Visual Attention\n",
      "  Going From Image to Video Saliency: Augmenting Image Salience With Dynamic Attentional Push\n",
      "  Revisiting Salient Object Detection: Simultaneous Detection, Ranking, and Subitizing of Multiple Salient Objects\n",
      "  Flow Guided Recurrent Neural Encoder for Video Salient Object Detection\n",
      "  PiCANet: Learning Pixel-Wise Contextual Attention for Saliency Detection\n",
      "  Detect Globally, Refine Locally: A Novel Approach to Saliency Detection\n",
      "  Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\n",
      "  Salient Object Detection Driven by Fixation Prediction\n",
      "  Weakly-Supervised Semantic Segmentation by Iteratively Mining Common Object Features\n",
      "  Active Fixation Control to Predict Saccade Sequences\n",
      "  Gaze Prediction in Dynamic 360Â° Immersive Videos\n",
      "  Learning to Promote Saliency Detectors\n",
      "  A Bi-Directional Message Passing Model for Salient Object Detection\n",
      "  Deep Unsupervised Saliency Detection: A Multiple Noisy Labeling Perspective\n",
      "  Progressive Attention Guided Recurrent Network for Salient Object Detection\n",
      "==============\n",
      "\n",
      "CLUSTER 7: 3D objects\n",
      "\n",
      "  LiDAR-Video Driving Dataset: Learning Driving Policies Effectively\n",
      "  SurfConv: Bridging 3D and 2D Convolution for RGBD Images\n",
      "  3D Semantic Segmentation With Submanifold Sparse Convolutional Networks\n",
      "  Pointwise Convolutional Neural Networks\n",
      "  Recurrent Slice Networks for 3D Segmentation of Point Clouds\n",
      "  Large-Scale Point Cloud Semantic Segmentation With Superpoint Graphs\n",
      "  PointGrid: A Deep Network for 3D Shape Understanding\n",
      "  SO-Net: Self-Organizing Network for Point Cloud Analysis\n",
      "  Frustum PointNets for 3D Object Detection From RGB-D Data\n",
      "  A Network Architecture for Point Cloud Classification via Automatic Depth Images Generation\n",
      "  Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling\n",
      "  SPLATNet: Sparse Lattice Networks for Point Cloud Processing\n",
      "  Tangent Convolutions for Dense Prediction in 3D\n",
      "  PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition\n",
      "  Deep Parametric Continuous Convolutional Neural Networks\n",
      "  SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation\n",
      "  Multi-Level Fusion Based 3D Object Detection From Monocular Images\n",
      "  PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation\n",
      "  FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation\n",
      "  PIXOR: Real-Time 3D Object Detection From Point Clouds\n",
      "  PU-Net: Point Cloud Upsampling Network\n",
      "  VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection\n",
      "==============\n",
      "\n",
      "CLUSTER 4: Text detection/recognition\n",
      "\n",
      "  Edit Probability for Scene Text Recognition\n",
      "  Multimodal Visual Concept Learning With Weakly Supervised Techniques\n",
      "  AON: Towards Arbitrarily-Oriented Text Recognition\n",
      "  A Face-to-Face Neural Conversation Model\n",
      "  A Neural Multi-Sequence Alignment TeCHnique (NeuMATCH)\n",
      "  Finding Beans in Burgers: Deep Semantic-Visual Embedding With Localization\n",
      "  Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval With Generative Models\n",
      "  An End-to-End TextSpotter With Explicit Alignment and Attention\n",
      "  Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis\n",
      "  Learning Semantic Concepts and Order for Image and Sentence Matching\n",
      "  Deep Sparse Coding for Invariant Multimodal Halle Berry Neurons\n",
      "  Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval\n",
      "  Rotation-Sensitive Regression for Oriented Scene Text Detection\n",
      "  FOTS: Fast Oriented Text Spotting With a Unified Network\n",
      "  Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation\n",
      "  Connecting Pixels to Privacy and Utility: Automatic Redaction of Private Information in Images\n",
      "  Attentive Generative Adversarial Network for Raindrop Removal From a Single Image\n",
      "  MovieGraphs: Towards Understanding Human-Centric Situations From Videos\n",
      "  Geometry-Aware Scene Text Detection With Instance Transformation Network\n",
      "  TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays\n",
      "  Bidirectional Retrieval Made Simple\n",
      "  AttnGAN: Fine-Grained Text to Image Generation With Attentional Generative Adversarial Networks\n",
      "  End-to-End Convolutional Semantic Embeddings\n",
      "  Generative Image Inpainting With Contextual Attention\n",
      "==============\n",
      "\n",
      "CLUSTER 11: Object recognition from very few examples\n",
      "\n",
      "  Learning Attribute Representations With Localization for Flexible Fashion Search\n",
      "  Preserving Semantic Relations for Zero-Shot Learning\n",
      "  Memory Matching Networks for One-Shot Image Recognition\n",
      "  Compare and Contrast: Learning Prominent Visual Differences\n",
      "  Zero-Shot Visual Recognition Using Semantics-Preserving Adversarial Embedding Networks\n",
      "  Dynamic Few-Shot Visual Learning Without Forgetting\n",
      "  Context Embedding Networks\n",
      "  CLEAR: Cumulative LEARning for One-Shot One-Class Image Recognition\n",
      "  Hierarchical Novelty Detection for Visual Object Recognition\n",
      "  Multi-Label Zero-Shot Learning With Structured Knowledge Graphs\n",
      "  Discriminative Learning of Latent Features for Zero-Shot Recognition\n",
      "  Learning From Noisy Web Data With Category-Level Supervision\n",
      "  Webly Supervised Learning Meets Zero-Shot Learning: A Hybrid Approach for Fine-Grained Classification\n",
      "  Low-Shot Learning With Imprinted Weights\n",
      "  Few-Shot Image Recognition by Predicting Parameters From Activations\n",
      "  Zero-Shot Sketch-Image Hashing\n",
      "  Transductive Unbiased Embedding for Zero-Shot Learning\n",
      "  Learning to Compare: Relation Network for Few-Shot Learning\n",
      "  Generalized Zero-Shot Learning via Synthesized Examples\n",
      "  Low-Shot Learning From Imaginary Data\n",
      "  Zero-Shot Recognition via Semantic Embeddings and Knowledge Graphs\n",
      "  Feature Generating Networks for Zero-Shot Learning\n",
      "  Zero-Shot Kernel Learning\n",
      "  HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization\n",
      "  A Generative Adversarial Approach for Zero-Shot Learning From Noisy Texts\n",
      "==============\n",
      "\n",
      "CLUSTER 21: Tracking\n",
      "\n",
      "  Rolling Shutter and Radial Distortion Are Features for High Frame Rate Multi-Camera Tracking\n",
      "  Towards Dense Object Tracking in a 2D Honeybee Hive\n",
      "  WILDTRACK: A Multi-Camera HD Dataset for Dense Unscripted Pedestrian Detection\n",
      "  Fast and Accurate Online Video Object Segmentation via Tracking Parts\n",
      "  Context-Aware Deep Feature Compression for High-Speed Visual Tracking\n",
      "  Hyperparameter Optimization for Tracking With Continuous Deep Q-Learning\n",
      "  A Twofold Siamese Network for Real-Time Object Tracking\n",
      "  CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes\n",
      "  High Performance Visual Tracking With Siamese Region Proposal Network\n",
      "  Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking\n",
      "  DecideNet: Counting Varying Density Crowds Through Attention Guided Detection and Density Estimation\n",
      "  Leveraging Unlabeled Data for Crowd Counting by Learning to Rank\n",
      "  People, Penguins and Petri Dishes: Adapting Object Counting Models to New Visual Domains and Object Types Without Forgetting\n",
      "  Efficient Diverse Ensemble for Discriminative Co-Tracking\n",
      "  Fusing Crowd Density Maps and Visual Object Trackers for People Tracking in Crowd Scenes\n",
      "  Divide and Grow: Capturing Huge Diversity in Crowd Images With Incrementally Growing CNN\n",
      "  Crowd Counting via Adversarial Cross-Scale Consistency Pursuit\n",
      "  Crowd Counting With Deep Negative Correlation Learning\n",
      "  VITAL: VIsual Tracking via Adversarial Learning\n",
      "  Correlation Tracking via Joint Discrimination and Reliability Learning\n",
      "  Learning Spatial-Aware Regressions for Visual Tracking\n",
      "  High-Speed Tracking With Multi-Kernel Correlation Filters\n",
      "  Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking\n",
      "  Multi-Cue Correlation Filters for Robust Visual Tracking\n",
      "  SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation\n",
      "  A Causal And-Or Graph Model for Visibility Fluent Reasoning in Tracking Interacting Objects\n",
      "  End-to-End Flow Correlation Tracking With Spatial-Temporal Attention\n",
      "==============\n",
      "\n",
      "CLUSTER 2: Self-Localisation and Mapping (SLAM) and 3D reconstruction\n",
      "\n",
      "  Real-Time Monocular Depth Estimation Using Synthetic Data With Domain Adaptation via Image Style Transfer\n",
      "  CodeSLAM â Learning a Compact, Optimisable Representation for Dense Visual SLAM\n",
      "  Deep Ordinal Regression Network for Monocular Depth Estimation\n",
      "  Fight Ill-Posedness With Ill-Posedness: Single-Shot Variational Depth Super-Resolution From Shading\n",
      "  Robust Depth Estimation From Auto Bracketed Images\n",
      "  Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics\n",
      "  Recurrent Scene Parsing With Perspective Understanding in the Loop\n",
      "  Single-Image Depth Estimation Based on Fourier Domain Analysis\n",
      "  Depth-Aware Stereo Video Retargeting\n",
      "  MegaDepth: Learning Single-View Depth Prediction From Internet Photos\n",
      "  Geometry-Aware Deep Network for Single-Image Novel View Synthesis\n",
      "  PlaneNet: Piece-Wise Planar Reconstruction From a Single RGB Image\n",
      "  Unsupervised Learning of Depth and Ego-Motion From Monocular Video Using 3D Geometric Constraints\n",
      "  RayNet: Learning Volumetric 3D Reconstruction With Ray Potentials\n",
      "  Learning Patch Reconstructability for Accelerating Multi-View Stereo\n",
      "  GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation\n",
      "  Soccer on Your Tabletop\n",
      "  Im2Pano3D: Extrapolating 360Â° Structure and Semantics Beyond the Field of View\n",
      "  Aperture Supervision for Monocular Depth Estimation\n",
      "  Deep End-to-End Time-of-Flight Imaging\n",
      "  Mix and Match Networks: Encoder-Decoder Alignment for Zero-Pair Image Translation\n",
      "  Monocular Relative Depth Perception With Web Stereo Data Supervision\n",
      "  PAD-Net: Multi-Tasks Guided Prediction-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing\n",
      "  Structured Attention Guided Convolutional Neural Fields for Monocular Depth Estimation\n",
      "  Automatic 3D Indoor Scene Modeling From Single Panorama\n",
      "  LEGO: Learning Edge With Geometry All at Once by Watching Videos\n",
      "  Polarimetric Dense Monocular SLAM\n",
      "  Unsupervised Learning of Monocular Depth Estimation and Visual Odometry With Deep Feature Reconstruction\n",
      "  Deep Depth Completion of a Single RGB-D Image\n",
      "==============\n",
      "\n",
      "CLUSTER 16: Visual questions answering\n",
      "\n",
      "  Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\n",
      "  Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\n",
      "  Visual Question Reasoning on General Dependency Tree\n",
      "  Cross-Dataset Adaptation for Visual Question Answering\n",
      "  Embodied Question Answering\n",
      "  Visual Grounding via Accumulated Attention\n",
      "  Stacked Latent Attention for Multimodal Reasoning\n",
      "  Motion-Appearance Co-Memory Networks for Video Question Answering\n",
      "  IQA: Visual Question Answering in Interactive Environments\n",
      "  VizWiz Grand Challenge: Answering Visual Questions From Blind People\n",
      "  Learning Answer Embeddings for Visual Question Answering\n",
      "  Two Can Play This Game: Visual Dialog With Discriminative Question Generation and Answering\n",
      "  DVQA: Understanding Data Visualizations via Question Answering\n",
      "  Textbook Question Answering Under Instructor Guidance With Memory Networks\n",
      "  Visual Question Generation as Dual Task of Visual Question Answering\n",
      "  Focal Visual-Text Attention for Visual Question Answering\n",
      "  IVQA: Inverse Visual Question Answering\n",
      "  Visual Question Answering With Memory-Augmented Networks\n",
      "  Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning\n",
      "  FlipDial: A Generative Model for Two-Way Visual Dialogue\n",
      "  Learning by Asking Questions\n",
      "  Improved Fusion of Visual and Language Representations by Dense Symmetric Co-Attention for Visual Question Answering\n",
      "  Multimodal Explanations: Justifying Decisions and Pointing to the Evidence\n",
      "  Differential Attention for Visual Question Answering\n",
      "  Customized Image Narrative Generation via Interactive Visual Question Generation and Answering\n",
      "  Learning Visual Knowledge Memory Networks for Visual Question Answering\n",
      "  Tips and Tricks for Visual Question Answering: Learnings From the 2017 Challenge\n",
      "  Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning\n",
      "  Fooling Vision and Language Models Despite Localization and Attention Mechanism\n",
      "  Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\n",
      "==============\n",
      "\n",
      "CLUSTER 8: Re-identification\n",
      "\n",
      "  Multi-Level Factorisation Net for Person Re-Identification\n",
      "  Group Consistent Similarity Learning via Deep CRF for Person Re-Identification\n",
      "  Video Person Re-Identification With Competitive Snippet-Similarity Aggregation and Co-Attentive Snippet Embedding\n",
      "  Efficient and Deep Person Re-Identification Using Multi-Level Similarity\n",
      "  Deep Spatial Feature Reconstruction for Partial Person Re-Identification: Alignment-Free Approach\n",
      "  Adversarially Occluded Samples for Person Re-Identification\n",
      "  Unifying Identification and Context Learning for Person Recognition\n",
      "  Human Semantic Parsing for Person Re-Identification\n",
      "  Diversity Regularized Spatiotemporal Attention for Video-Based Person Re-Identification\n",
      "  Harmonious Attention Network for Person Re-Identification\n",
      "  Pose Transferrable Person Re-Identification\n",
      "  Unsupervised Cross-Dataset Person Re-Identification by Transfer Learning of Spatial-Temporal Patterns\n",
      "  Features for Multi-Target Multi-Camera Tracking and Re-Identification\n",
      "  Exploiting Transitivity for Learning Person Re-Identification Models on a Budget\n",
      "  A Pose-Sensitive Embedding for Person Re-Identification With Expanded Cross Neighborhood Re-Ranking\n",
      "  Deep Group-Shuffling Random Walk for Person Re-Identification\n",
      "  End-to-End Deep Kronecker-Product Matching for Person Re-Identification\n",
      "  Dual Attention Matching Network for Context-Aware Feature Sequence Based Person Re-Identification\n",
      "  Actor and Observer: Joint Modeling of First and Third-Person Videos\n",
      "  Mask-Guided Contrastive Attention Model for Person Re-Identification\n",
      "  Eliminating Background-Bias for Robust Person Re-Identification\n",
      "  Person Re-Identification With Cascaded Pairwise Convolutions\n",
      "  Resource Aware Person Re-Identification Across Multiple Resolutions\n",
      "  Transferable Joint Attribute-Identity Deep Learning for Unsupervised Person Re-Identification\n",
      "  Person Transfer GAN to Bridge Domain Gap for Person Re-Identification\n",
      "  Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning\n",
      "  Attention-Aware Compositional Network for Person Re-Identification\n",
      "  Multi-Shot Pedestrian Re-Identification via Sequential Decision Making\n",
      "  Camera Style Adaptation for Person Re-Identification\n",
      "  Easy Identification From Better Constraints: Multi-Shot Person Re-Identification From Reference Constraints\n",
      "  Viewpoint-Aware Attentive Multi-View Inference for Vehicle Re-Identification\n",
      "==============\n",
      "\n",
      "CLUSTER 20: 3D reconstruction\n",
      "\n",
      "  Image Collection Pop-Up: 3D Reconstruction and Clustering of Rigid and Non-Rigid Categories\n",
      "  Video Based Reconstruction of 3D People Models\n",
      "  Learning Distributions of Shape Trajectories From Longitudinal Datasets: A Hierarchical Model on a Manifold of Diffeomorphisms\n",
      "  ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans\n",
      "  Planar Shape Detection at Structural Scales\n",
      "  GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition\n",
      "  Neural 3D Mesh Renderer\n",
      "  Surface Networks\n",
      "  Scalable Dense Non-Rigid Structure-From-Motion: A Grassmannian Perspective\n",
      "  3D-RCNN: Instance-Level 3D Object Reconstruction via Render-and-Compare\n",
      "  4D Human Body Correspondences From Panoramic Depth Maps\n",
      "  Structure From Recurrent Motion: From Rigidity to Recurrency\n",
      "  Deep Marching Cubes: Learning Explicit Surface Representations\n",
      "  Deformable Shape Completion With Graph Convolutional Autoencoders\n",
      "  Manifold Learning in Quotient Spaces\n",
      "  Tags2Parts: Discovering Semantic Regions From Shape Tags\n",
      "  Im2Struct: Recovering 3D Shape Structure From a Single RGB Image\n",
      "  Geometry-Aware Network for Non-Rigid Shape Prediction From a Single View\n",
      "  3D Object Detection With Latent Support Surfaces\n",
      "  Matryoshka Networks: Predicting 3D Geometry via Nested Shape Layers\n",
      "  CSGNet: Neural Shape Parser for Constructive Solid Geometry\n",
      "  Pixels, Voxels, and Views: A Study of Shape Representations for Single View 3D Object Shape Prediction\n",
      "  SobolevFusion: 3D Reconstruction of Scenes Undergoing Free Non-Rigid Motion\n",
      "  Learning 3D Shape Completion From Laser Scan Data With Weak Supervision\n",
      "  Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling\n",
      "  Variational Autoencoders for Deforming 3D Mesh Models\n",
      "  Factoring Shape, Pose, and Layout From the 2D Image of a 3D Scene\n",
      "  FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis\n",
      "  Attentional ShapeContextNet for Point Cloud Recognition\n",
      "  Shape From Shading Through Shape Evolution\n",
      "  DoubleFusion: Real-Time Capture of Human Performances With Inner Body Shapes From a Single Depth Sensor\n",
      "  Lions and Tigers and Bears: Capturing Non-Rigid, 3D, Articulated Shape From Images\n",
      "==============\n",
      "\n",
      "CLUSTER 5: Transfer learning, domain adaptation and adversarial networks\n",
      "\n",
      "  Partial Transfer Learning With Selective Adversarial Networks\n",
      "  Coupled End-to-End Transfer Learning With Generalized Fisher Information\n",
      "  Domain Adaptive Faster R-CNN for Object Detection in the Wild\n",
      "  ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes\n",
      "  Re-Weighted Adversarial Adaptation Network for Unsupervised Domain Adaptation\n",
      "  StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation\n",
      "  Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning\n",
      "  Image-Image Domain Adaptation With Preserved Self-Similarity and Domain-Dissimilarity for Person Re-Identification\n",
      "  Conditional Generative Adversarial Network for Structured Domain Adaptation\n",
      "  Unsupervised Correlation Analysis\n",
      "  Duplex Generative Adversarial Network for Unsupervised Domain Adaptation\n",
      "  Deep Cross-Media Knowledge Transfer\n",
      "  Cross-Domain Weakly-Supervised Object Detection Through Progressive Domain Adaptation\n",
      "  Deep Face Detector Adaptation Without Negative Transfer or Catastrophic Forgetting\n",
      "  AdaDepth: Unsupervised Content Congruent Adaptation for Depth Estimation\n",
      "  Domain Generalization With Adversarial Feature Learning\n",
      "  Conditional Image-to-Image Translation\n",
      "  Detach and Adapt: Learning Cross-Domain Disentangled Deep Representation\n",
      "  Boosting Domain Adaptation by Discovering Latent Domains\n",
      "  Image to Image Translation for Domain Adaptation\n",
      "  Unsupervised Domain Adaptation With Similarity Learning\n",
      "  Efficient Parametrization of Multi-Domain Deep Neural Networks\n",
      "  Cross-Domain Self-Supervised Multi-Task Feature Learning Using Synthetic Imagery\n",
      "  Residual Parameter Transfer for Deep Domain Adaptation\n",
      "  From Source to Target and Back: Symmetric Bi-Directional Adaptive GAN\n",
      "  Generate to Adapt: Aligning Domains Using Generative Adversarial Networks\n",
      "  Learning From Synthetic Data: Addressing Domain Shift for Semantic Segmentation\n",
      "  Learning to Adapt Structured Output Space for Semantic Segmentation\n",
      "  Adversarial Feature Augmentation for Unsupervised Domain Adaptation\n",
      "  Deep Cocktail Network: Multi-Source Unsupervised Domain Adaptation With Category Shift\n",
      "  Aligning Infinite-Dimensional Covariance Matrices in Reproducing Kernel Hilbert Spaces for Domain Adaptation\n",
      "  Collaborative and Adversarial Network for Unsupervised Domain Adaptation\n",
      "  Fully Convolutional Adaptation Networks for Semantic Segmentation\n",
      "  Importance Weighted Adversarial Nets for Partial Domain Adaptation\n",
      "==============\n",
      "\n",
      "CLUSTER 19: Lighting models\n",
      "\n",
      "  A Revised Underwater Image Formation Model\n",
      "  Light Field Intrinsics With a Deep Encoder-Decoder Network\n",
      "  Lose the Views: Limited Angle CT Reconstruction via Implicit Sinogram Completion\n",
      "  Inferring Light Fields From Shadows\n",
      "  Curve Reconstruction via the Global Statistics of Natural Curves\n",
      "  CNN Based Learning Using Reflection and Retinex Models for Intrinsic Image Decomposition\n",
      "  Sparse Photometric 3D Face Reconstruction Guided by Morphable Models\n",
      "  Learning to See in the Dark\n",
      "  TOM-Net: Learning Transparent Object Matting From a Single Image\n",
      "  Intrinsic Image Transformation via Scale Space Decomposition\n",
      "  Sparse, Smart Contours to Represent and Edit Images\n",
      "  Revisiting Deep Intrinsic Image Decompositions\n",
      "  Texture Mapping for 3D Reconstruction With RGB-D Sensor\n",
      "  Photometric Stereo in Participating Media Considering Shape-Dependent Forward Scatter\n",
      "  Multispectral Image Intrinsic Decomposition via Subspace Constraint\n",
      "  Illuminant Spectra-Based Source Separation Using Flash Photography\n",
      "  Mesoscopic Facial Geometry Inference Using Deep Neural Networks\n",
      "  Learning Intrinsic Image Decomposition From Watching the World\n",
      "  A Prior-Less Method for Multi-Face Tracking in Unconstrained Videos\n",
      "  DocUNet: Document Image Unwarping via a Stacked U-Net\n",
      "  LIME: Live Intrinsic Material Estimation\n",
      "  Optimal Structured Light Ã  La Carte\n",
      "  Memory Based Online Learning of Deep Representations From Video Streams\n",
      "  Semi-Parametric Image Synthesis\n",
      "  Seeing Temporal Modulation of Lights From Standard Cameras\n",
      "  SfSNet: Learning Shape, Reflectance and Illuminance of Faces `in the Wild'\n",
      "  EPINET: A Fully-Convolutional Neural Network Using Epipolar Geometry for Depth From Light Field Images\n",
      "  Depth and Transient Imaging With Compressive SPAD Array Cameras\n",
      "  Time-Resolved Light Transport Decomposition for Thermal Photometric Stereo\n",
      "  Generating Synthetic X-Ray Images of a Person From the Surface Geometry\n",
      "  Self-Calibrating Polarising Radiometric Calibration\n",
      "  Modifying Non-Local Variations Across Multiple Views\n",
      "  Robust Hough Transform Based 3D Reconstruction From Circular Light Fields\n",
      "  A Hierarchical Generative Model for Eye Image Synthesis and Eye Gaze Estimation\n",
      "  Salience Guided Depth Calibration for Perceptually Optimized Compressive Light Field 3D Display\n",
      "  Trapping Light for Time of Flight\n",
      "  Clinical Skin Lesion Diagnosis Using Representations Inspired by Dermatologist Criteria\n",
      "  Discovering Point Lights With Intensity Distance Fields\n",
      "==============\n",
      "\n",
      "CLUSTER 23: Point clouds correspondences and matching\n",
      "\n",
      "  Geometric Multi-Model Fitting With a Convex Relaxation Algorithm\n",
      "  Five-Point Fundamental Matrix Estimation for Uncalibrated Cameras\n",
      "  Egocentric Basketball Motion Planning From a Single First-Person Image\n",
      "  A Minimalist Approach to Type-Agnostic Detection of Quadrics in Point Clouds\n",
      "  A Certifiably Globally Optimal Solution to the Non-Minimal Relative Pose Problem\n",
      "  PPFNet: Global Context Aware Local Features for Robust 3D Point Matching\n",
      "  Fast Monte-Carlo Localization on Aerial Vehicles Using Approximate Continuous Belief Representations\n",
      "  Rotation Averaging and Strong Duality\n",
      "  MapNet: An Allocentric Spatial Memory for Mapping Environments\n",
      "  A Perceptual Measure for Deep Single Image Camera Calibration\n",
      "  pOSE: Pseudo Object Space Error for Initialization-Free Bundle Adjustment\n",
      "  Globally Optimal Inlier Set Maximization for Atlanta Frame Estimation\n",
      "  Improving Color Reproduction Accuracy on Cameras\n",
      "  Indoor RGB-D Compass From a Single Line and Plane\n",
      "  Latent RANSAC\n",
      "  Solving the Perspective-2-Point Problem for Flying-Camera Photo Composition\n",
      "  A Robust Method for Strong Rolling Shutter Effects Correction Using Lines With Automatic Feature Selection\n",
      "  Camera Pose Estimation With Unknown Principal Point\n",
      "  Statistical Tomography of Microscopic Life\n",
      "  Reconstructing Thin Structures of Manifold Surfaces by Integrating Spatial Curves\n",
      "  ICE-BA: Incremental, Consistent and Efficient Bundle Adjustment for Visual-Inertial SLAM\n",
      "  Analytical Modeling of Vanishing Points and Curves in Catadioptric Cameras\n",
      "  Divide and Conquer for Full-Resolution Light Field Deblurring\n",
      "  Spline Error Weighting for Robust Visual-Inertial Fusion\n",
      "  Alternating-Stereo VINS: Observability Analysis and Performance Evaluation\n",
      "  Augmenting Crowd-Sourced 3D Reconstructions Using Semantic Detections\n",
      "  Radially-Distorted Conjugate Translations\n",
      "  3D Registration of Curves and Surfaces Using Local Differential Information\n",
      "  CarFusion: Combining Point Tracking and Part Detection for Dynamic 3D Reconstruction of Vehicles\n",
      "  Estimation of Camera Locations in Highly Corrupted Scenarios: All About That Base, No Shape Trouble\n",
      "  Tracking Multiple Objects Outside the Line of Sight Using Speckle Imaging\n",
      "  Consensus Maximization for Semantic Region Correspondences\n",
      "  Jerk-Aware Video Acceleration Magnification\n",
      "  Two-Stream Convolutional Networks for Dynamic Texture Synthesis\n",
      "  Occlusion-Aware Rolling Shutter Rectification of 3D Scenes\n",
      "  Inverse Composition Discriminative Optimization for Point Cloud Registration\n",
      "  Motion Segmentation by Exploiting Complementary Geometric Models\n",
      "  Future Person Localization in First-Person Videos\n",
      "  Learning to Find Good Correspondences\n",
      "  3D Semantic Trajectory Reconstruction From 3D Pixel Continuum\n",
      "  Reflection Removal for Large-Scale 3D Point Clouds\n",
      "  A Fast Resection-Intersection Method for the Known Rotation Problem\n",
      "  Very Large-Scale Global SfM by Distributed Motion Averaging\n",
      "  Baseline Desensitizing in Translation Averaging\n",
      "==============\n",
      "\n",
      "CLUSTER 6: Face detection/recognition\n",
      "\n",
      "  Modeling Facial Geometry Using Compositional VAEs\n",
      "  Finding Tiny Faces in the Wild With Generative Adversarial Network\n",
      "  Towards Open-Set Identity Preserving Face Synthesis\n",
      "  Super-FAN: Integrated Facial Landmark Localization and Super-Resolution of Real-World Low Resolution Faces in Arbitrary Poses With GANs\n",
      "  Pose-Robust Face Recognition via Deep Residual Equivariant Mapping\n",
      "  FSRNet: End-to-End Learning Face Super-Resolution With Facial Priors\n",
      "  Facelet-Bank for Fast Portrait Manipulation\n",
      "  4DFAB: A Large Scale 4D Database for Facial Expression Analysis and Biometric Applications\n",
      "  UV-GAN: Adversarial Facial UV Map Completion for Pose-Invariant Face Recognition\n",
      "  Style Aggregated Network for Facial Landmark Detection\n",
      "  Supervision-by-Registration: An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors\n",
      "  Wing Loss for Robust Facial Landmark Localisation With Convolutional Neural Networks\n",
      "  Unsupervised Training for 3D Morphable Model Regression\n",
      "  Learning From Millions of 3D Scans for Large-Scale 3D Face Recognition\n",
      "  Dynamic Feature Learning for Partial Face Recognition\n",
      "  Improving Landmark Localization With Semi-Supervised Learning\n",
      "  Pose-Guided Photorealistic Face Rotation\n",
      "  InverseFaceNet: Deep Monocular Inverse Face Rendering\n",
      "  Disentangling 3D Pose in a Dendritic CNN for Unconstrained 2D Face Alignment\n",
      "  Disentangling Features in 3D Face Shapes for Joint Face Reconstruction and Recognition\n",
      "  Learning Deep Models for Face Anti-Spoofing: Binary or Auxiliary Supervision\n",
      "  Probabilistic Joint Face-Skull Modelling for Facial Reconstruction\n",
      "  Robust Facial Landmark Detection via a Fully-Convolutional Local-Global Context Network\n",
      "  Direct Shape Regression Networks for End-to-End Face Alignment\n",
      "  Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching\n",
      "  Deep Semantic Face Deblurring\n",
      "  FaceID-GAN: Learning a Symmetry Three-Player GAN for Identity-Preserving Face Synthesis\n",
      "  Real-Time Rotation-Invariant Face Detection With Progressive Calibration Networks\n",
      "  Beyond Trade-Off: Accelerate FCN-Based Face Detector With Higher Accuracy\n",
      "  Natural and Effective Obfuscation by Head Inpainting\n",
      "  Self-Supervised Multi-Level Face Model Learning for Monocular Reconstruction at Over 250 Hz\n",
      "  Extreme 3D Face Reconstruction: Seeing Through Occlusions\n",
      "  Nonlinear 3D Face Morphable Model\n",
      "  CosFace: Large Margin Cosine Loss for Deep Face Recognition\n",
      "  Every Smile Is Unique: Landmark-Guided Diverse Smile Generation\n",
      "  Face Aging With Identity-Preserved Conditional Generative Adversarial Networks\n",
      "  Alive Caricature From 2D to 3D\n",
      "  Look at Boundary: A Boundary-Aware Face Alignment Algorithm\n",
      "  Facial Expression Recognition by De-Expression Residue Learning\n",
      "  Learning Face Age Progression: A Pyramid Architecture of GANs\n",
      "  Super-Resolving Very Low-Resolution Face Images With Supplementary Attributes\n",
      "  Joint Pose and Expression Modeling for Facial Expression Recognition\n",
      "  Unsupervised Discovery of Object Landmarks as Structural Representations\n",
      "  Towards Pose Invariant Face Recognition in the Wild\n",
      "  Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Faces\n",
      "  Seeing Small Faces From Robust Anchor's Perspective\n",
      "==============\n",
      "\n",
      "CLUSTER 15: Pose estimation\n",
      "\n",
      "  PoseTrack: A Benchmark for Human Pose Estimation and Tracking\n",
      "  Augmented Skeleton Space Transfer for Depth-Based Hand Pose Estimation\n",
      "  Synthesizing Images of Humans in Unseen Poses\n",
      "  Learning Less Is More - 6D Camera Localization via 3D Surface Regression\n",
      "  Geometry-Aware Learning of Maps for Camera Localization\n",
      "  Hybrid Camera Pose Estimation\n",
      "  Cascaded Pyramid Network for Multi-Person Pose Estimation\n",
      "  PoTion: Pose MoTion Representation for Action Recognition\n",
      "  First-Person Hand Action Benchmark With RGB-D Videos and 3D Hand Pose Annotations\n",
      "  Hand PointNet: 3D Hand Pose Estimation Using Point Sets\n",
      "  Detect-and-Track: Efficient Pose Estimation in Videos\n",
      "  3D Pose Estimation and 3D Model Retrieval for Objects in the Wild\n",
      "  DensePose: Dense Human Pose Estimation in the Wild\n",
      "  VITON: An Image-Based Virtual Try-On Network\n",
      "  Total Capture: A 3D Deformation Model for Tracking Faces, Hands, and Bodies\n",
      "  End-to-End Recovery of Human Shape and Pose\n",
      "  RotationNet: Joint Object Categorization and Pose Estimation Using Multiviews From Unsupervised Viewpoints\n",
      "  Feature Space Transfer for Data Augmentation\n",
      "  Recognizing Human Actions as the Evolution of Pose Estimation Maps\n",
      "  2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning\n",
      "  Disentangled Person Image Generation\n",
      "  3D Human Sensing, Action and Emotion Recognition in Robot Assisted Therapy of Children With Autism\n",
      "  V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation From a Single Depth Map\n",
      "  GANerated Hands for Real-Time 3D Hand Tracking From Monocular RGB\n",
      "  Human Pose Estimation With Parsing Induced Learner\n",
      "  Learning to Estimate 3D Human Pose and Shape From a Single Color Image\n",
      "  Ordinal Depth Supervision for 3D Human Pose Estimation\n",
      "  Jointly Optimize Data Augmentation and Network Training: Adversarial Data Augmentation in Human Pose Estimation\n",
      "  Learning Pose Specific Representations by Predicting Different Views\n",
      "  Unsupervised Person Image Synthesis in Arbitrary Poses\n",
      "  Feature Mapping for Learning Fast and Accurate 3D Pose Inference From Synthetic Images\n",
      "  Learning Monocular 3D Human Pose Estimation From Multi-View Images\n",
      "  Audio to Body Dynamics\n",
      "  Multistage Adversarial Losses for Pose-Based Human Image Synthesis\n",
      "  Deformable GANs for Pose-Based Human Image Generation\n",
      "  Cross-Modal Deep Variational Hand Pose Estimation\n",
      "  Real-Time Seamless Single Shot 6D Object Pose Prediction\n",
      "  Multi-View Consistency as Supervisory Signal for Learning Shape and Pose Prediction\n",
      "  Dense 3D Regression for Hand Pose Estimation\n",
      "  DeLS-3D: Deep Localization and Segmentation With a 3D Semantic Map\n",
      "  Learning Depth From Monocular Videos Using Direct Methods\n",
      "  3D Human Pose Estimation in the Wild by Adversarial Learning\n",
      "  Depth-Based 3D Hand Pose Estimation: From Current Achievements to Future Goals\n",
      "  Taskonomy: Disentangling Task Transfer Learning\n",
      "  Human Appearance Transfer\n",
      "  Monocular 3D Pose and Shape Estimation of Multiple People in Natural Scenes - The Importance of Multiple Scene Constraints\n",
      "  Through-Wall Human Pose Estimation Using Radio Signals\n",
      "==============\n",
      "\n",
      "CLUSTER 9: Image/video captioning, object detection\n",
      "\n",
      "  Convolutional Image Captioning\n",
      "  Glimpse Clouds: Human Activity Recognition From Unstructured Feature Points\n",
      "  Accurate and Diverse Sampling of Sequences Based on a âBest of Manyâ Sample Objective\n",
      "  Long-Term On-Board Prediction of People in Traffic Scenes Under Uncertainty\n",
      "  Neural Sign Language Translation\n",
      "  GroupCap: Group-Based Image Captioning With Structured Relevance and Diversity Constraints\n",
      "  Knowledge Aided Consistency for Weakly Supervised Phrase Grounding\n",
      "  Language-Based Image Editing With Recurrent Attentive Models\n",
      "  Regularizing RNNs for Caption Generation by Reconstructing the Past With the Present\n",
      "  Learning to Evaluate Image Captioning\n",
      "  AMNet: Memorability Estimation With Attention\n",
      "  Inferring Shared Attention in Social Scene Videos\n",
      "  Social GAN: Socially Acceptable Trajectories With Generative Adversarial Networks\n",
      "  MX-LSTM: Mixing Tracklets and Vislets to Jointly Forecast Trajectories and Head Poses\n",
      "  Direction-Aware Spatial Context Features for Shadow Detection\n",
      "  Referring Relationships\n",
      "  Independently Recurrent Neural Network (IndRNN): Building a Longer and Deeper RNN\n",
      "  Jointly Localizing and Describing Events for Dense Video Captioning\n",
      "  Referring Image Segmentation via Recurrent Refinement Networks\n",
      "  Tell Me Where to Look: Guided Attention Inference Network\n",
      "  Mobile Video Object Detection With Temporally-Aware Feature Maps\n",
      "  Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\n",
      "  Neural Baby Talk\n",
      "  Discriminability Objective for Training Descriptive Captions\n",
      "  LSTM Pose Machines\n",
      "  Attend and Interact: Higher-Order Object Interactions for Video Understanding\n",
      "  SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\n",
      "  Guide Me: Interacting With Deep Networks\n",
      "  Learning to Localize Sound Source in Visual Scenes\n",
      "  Attentive Fashion Grammar Network for Fashion Landmark Detection and Clothing Category Classification\n",
      "  Bidirectional Attentive Fusion With Context Gating for Dense Video Captioning\n",
      "  Categorizing Concepts With Basic Level for Vision-to-Language\n",
      "  M3: Multimodal Memory Modelling for Video Captioning\n",
      "  Reconstruction Network for Video Captioning\n",
      "  Video Captioning via Hierarchical Reinforcement Learning\n",
      "  Where and Why Are They Looking? Jointly Inferring Human Attention and Intentions in Complex Tasks\n",
      "  Interpretable Video Captioning via Trajectory Structured Localization\n",
      "  Encoding Crowd Interaction With Deep Neural Network for Pedestrian Trajectory Prediction\n",
      "  Making Convolutional Networks Recurrent for Visual Sequence Learning\n",
      "  Learning Compact Recurrent Neural Networks With Block-Term Tensor Decomposition\n",
      "  Unsupervised Textual Grounding: Linking Words to Image Concepts\n",
      "  Fine-Grained Video Captioning for Sports Narrative\n",
      "  MAttNet: Modular Attention Network for Referring Expression Comprehension\n",
      "  Grounding Referring Expressions in Images by Variational Context\n",
      "  Occluded Pedestrian Detection Through Guided Attention in CNNs\n",
      "  Weakly Supervised Phrase Localization With Multi-Scale Anchored Transformer Network\n",
      "  End-to-End Dense Video Captioning With Masked Transformer\n",
      "==============\n",
      "\n",
      "CLUSTER 10: Generative Adversarial Networks (GAN)\n",
      "\n",
      "  Defense Against Universal Adversarial Perturbations\n",
      "  On the Robustness of Semantic Segmentation Models to Adversarial Attacks\n",
      "  Visual Feature Attribution Using Wasserstein GANs\n",
      "  HashGAN: Deep Learning to Hash With Pair Conditional Wasserstein GAN\n",
      "  SGAN: An Alternative Training of Generative Adversarial Networks\n",
      "  Deep Photo Enhancer: Unpaired Learning for Image Enhancement From Photographs With GANs\n",
      "  SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis\n",
      "  Generative Modeling Using the Sliced Wasserstein Distance\n",
      "  Unsupervised Deep Generative Adversarial Hashing Network\n",
      "  Eye In-Painting With Exemplar Generative Adversarial Networks\n",
      "  Boosting Adversarial Attacks With Momentum\n",
      "  Deep Adversarial Metric Learning\n",
      "  A Variational U-Net for Conditional Appearance and Shape Generation\n",
      "  Robust Physical-World Attacks on Deep Learning Visual Classification\n",
      "  DiverseNet: When One Right Answer Is Not Enough\n",
      "  Learning Generative ConvNets via Multi-Grid Modeling and Sampling\n",
      "  Multi-Agent Diverse Generative Adversarial Networks\n",
      "  Learning Compositional Visual Concepts With Mutual Consistency\n",
      "  A Two-Step Disentanglement Method\n",
      "  Disentangling Factors of Variation by Mixing Them\n",
      "  Self-Supervised Feature Learning by Learning to Spot Artifacts\n",
      "  Generating a Fusion Image: One's Identity and Another's Shape\n",
      "  Generative Adversarial Image Synthesis With Decision Tree Latent Controller\n",
      "  Art of Singular Vectors and Universal Adversarial Perturbations\n",
      "  GAGAN: Geometry-Aware Generative Adversarial Networks\n",
      "  Wasserstein Introspective Neural Networks\n",
      "  Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser\n",
      "  ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing\n",
      "  DA-GAN: Instance-Level Image Translation by Deep Attention Generative Adversarial Networks\n",
      "  Matching Adversarial Networks\n",
      "  NAG: Network for Adversary Generation\n",
      "  Adversarial Data Programming: Using GANs to Relax the Bottleneck of Curated Labeled Data\n",
      "  Generative Adversarial Perturbations\n",
      "  Deflecting Adversarial Attacks With Pixel Deflection\n",
      "  Global Versus Localized Generative Adversarial Nets\n",
      "  Cross-View Image Synthesis Using Conditional GANs\n",
      "  Adversarially Learned One-Class Classifier for Novelty Detection\n",
      "  Logo Synthesis and Manipulation With Clustered Generative Adversarial Networks\n",
      "  Feature Super-Resolution: Make Machine See More Clearly\n",
      "  Rethinking Feature Distribution for Loss Functions in Image Classification\n",
      "  High-Resolution Image Synthesis and Semantic Manipulation With Conditional GANs\n",
      "  Interpret Neural Networks by Identifying Critical Data Routing Paths\n",
      "  Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal\n",
      "  Tagging Like Humans: Diverse and Distinct Image Annotation\n",
      "  Learning Descriptor Networks for 3D Shape Synthesis and Analysis\n",
      "  Photographic Text-to-Image Synthesis With a Hierarchically-Nested Adversarial Network\n",
      "  Translating and Segmenting Multimodal Medical Volumes With Cycle- and Shape-Consistency Generative Adversarial Network\n",
      "  Deep Adversarial Subspace Clustering\n",
      "==============\n",
      "\n",
      "CLUSTER 0: Object detection, video/object segmentation\n",
      "\n",
      "  CNN in MRF: Video Object Segmentation via Inference in a CNN-Based Higher-Order Spatio-Temporal MRF\n",
      "  The Best of Both Worlds: Combining CNNs and Geometric Constraints for Hierarchical Motion Segmentation\n",
      "  Deep Spatio-Temporal Random Fields for Efficient Video Segmentation\n",
      "  Blazingly Fast Video Object Segmentation With Pixel-Wise Metric Learning\n",
      "  Optimizing Video Object Detection via a Scale-Time Lattice\n",
      "  End-to-End Learning of Motion Representation for Video Understanding\n",
      "  What Have We Learned From Deep Representations for Action Recognition?\n",
      "  Im2Flow: Motion Hallucination From Static Images for Action Recognition\n",
      "  Controllable Video Generation With Sparse Trajectories\n",
      "  Motion-Guided Cascaded Refinement Network for Video Object Segmentation\n",
      "  What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\n",
      "  LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation\n",
      "  Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\n",
      "  Learning to Extract a Video Sequence From a Single Motion-Blurred Image\n",
      "  Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation\n",
      "  Free Supervision From Video Games\n",
      "  ClusterNet: Detecting Small Objects in Large Scenes by Exploiting Spatio-Temporal Information\n",
      "  Boundary Flow: A Siamese Network That Predicts Boundary Motion Without Training on Motion\n",
      "  Instance Embedding Transfer to Unsupervised Video Object Segmentation\n",
      "  Low-Latency Video Semantic Segmentation\n",
      "  Erase or Fill? Deep Joint Recurrent Rain Removal and Reconstruction in Videos\n",
      "  Future Frame Prediction for Anomaly Detection â A New Baseline\n",
      "  Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting With a Single Convolutional Net\n",
      "  PhaseNet for Video Frame Interpolation\n",
      "  Context-Aware Synthesis for Video Frame Interpolation\n",
      "  Semantic Video Segmentation by Gated Recurrent Flow Propagation\n",
      "  Fast Video Object Segmentation by Reference-Guided Mask Propagation\n",
      "  Real-World Repetition Estimation by Div, Grad and Curl\n",
      "  Frame-Recurrent Video Super-Resolution\n",
      "  A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos\n",
      "  Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\n",
      "  PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume\n",
      "  MoCoGAN: Decomposing Motion and Content for Video Generation\n",
      "  Neural Kinematic Networks for Unsupervised Motion Retargetting\n",
      "  Occlusion Aware Unsupervised Learning of Optical Flow\n",
      "  Learning and Using the Arrow of Time\n",
      "  Compressed Video Action Recognition\n",
      "  MoNet: Deep Motion Exploitation for Video Object Segmentation\n",
      "  Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks\n",
      "  Dynamic Video Segmentation Network\n",
      "  Structure Preserving Video Prediction\n",
      "  Efficient Video Object Segmentation via Network Modulation\n",
      "  Multi-Frame Quality Enhancement for Compressed Video\n",
      "  GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose\n",
      "  PoseFlow: A Deep Motion Representation for Understanding Human Behaviors in Videos\n",
      "  Recognize Actions by Disentangling Components of Dynamics\n",
      "  Visual to Sound: Generating Natural Sound for Videos in the Wild\n",
      "  Towards High Performance Video Object Detection\n",
      "  View Extrapolation of Human Body From a Single Image\n",
      "==============\n",
      "\n",
      "CLUSTER 14: Image/points registration, visual features\n",
      "\n",
      "  An Unsupervised Learning Model for Deformable Medical Image Registration\n",
      "  Graph-Cut RANSAC\n",
      "  KIPPI: KInetic Polygonal Partitioning of Images\n",
      "  DS*: Tighter Lifting-Free Convex Relaxations for Quadratic Matching Problems\n",
      "  Compassionately Conservative Balanced Cuts for Image Segmentation\n",
      "  Structured Set Matching Networks for One-Shot Part Labeling\n",
      "  On the Convergence of PatchMatch and Its Variants\n",
      "  SplineCNN: Fast Geometric Deep Learning With Continuous B-Spline Kernels\n",
      "  End-to-End Learning of Keypoint Detector and Descriptor for Pose Invariant 3D Matching\n",
      "  Local Descriptors Optimized for Average Precision\n",
      "  Triplet-Center Loss for Multi-View 3D Object Retrieval\n",
      "  CVM-Net: Cross-View Matching Network for Image-Based Ground-to-Aerial Geo-Localization\n",
      "  Distributable Consistent Multi-Object Matching\n",
      "  Learning to Parse Wireframes in Images of Man-Made Environments\n",
      "  Fast and Robust Estimation for Unit-Norm Constrained Linear Fitting Problems\n",
      "  Local and Global Optimization Techniques in Graph-Based Clustering\n",
      "  Fast Spectral Ranking for Similarity Search\n",
      "  Mining on Manifolds: Metric Learning Without Labels\n",
      "  Probabilistic Plant Modeling via Multi-View Image-to-Image Translation\n",
      "  CNN Driven Sparse Multi-Level B-Spline Image Registration\n",
      "  Matching Pixels Using Co-Occurrence Statistics\n",
      "  Learning Deep Descriptors With Scale-Aware Triplet Networks\n",
      "  Learned Shape-Tailored Descriptors for Segmentation\n",
      "  High-Order Tensor Regularization With Application to Attribute Ranking\n",
      "  Document Enhancement Using Visibility Detection\n",
      "  OATM: Occlusion Aware Template Matching by Consensus Set Maximization\n",
      "  Density Adaptive Point Set Registration\n",
      "  Continuous Relaxation of MAP Inference: A Nonconvex Perspective\n",
      "  Dimensionality's Blessing: Clustering Images by Underlying Distribution\n",
      "  Learning Multi-Instance Enriched Image Representations via Non-Greedy Ratio Maximization of the l1-Norm Distances\n",
      "  Efficient Subpixel Refinement With Symbolic Linear Predictors\n",
      "  Self-Supervised Learning of Geometrically Stable Features Through Probabilistic Introspection\n",
      "  Human-Centric Indoor Scene Synthesis Using Stochastic Grammar\n",
      "  Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking\n",
      "  End-to-End Weakly-Supervised Semantic Alignment\n",
      "  Benchmarking 6DOF Outdoor Visual Localization in Changing Conditions\n",
      "  Semantic Visual Localization\n",
      "  Inference in Higher Order MRF-MAP Problems With Small and Large Cliques\n",
      "  SoS-RSC: A Sum-of-Squares Polynomial Approach to Robustifying Subspace Clustering Algorithms\n",
      "  InLoc: Indoor Visual Localization With Dense Matching and View Synthesis\n",
      "  Efficient, Sparse Representation of Manifold Distance Matrices for Classical Scaling\n",
      "  Multi-Image Semantic Matching by Mining Consistent Features\n",
      "  Kernelized Subspace Pooling for Deep Local Descriptors\n",
      "  Deep Lesion Graphs in the Wild: Relationship Learning and Organization of Significant Radiology Image Findings in a Diverse Large-Scale Lesion Database\n",
      "  Content-Sensitive Supervoxels via Uniform Tessellations on Video Manifolds\n",
      "  Joint Cuts and Matching of Partitions in One Graph\n",
      "  Deep Learning of Graph Matching\n",
      "  Learning to Detect Features in Texture Images\n",
      "  LayoutNet: Reconstructing the 3D Room Layout From a Single RGB Image\n",
      "==============\n",
      "\n",
      "CLUSTER 1: Image processing\n",
      "\n",
      "  A High-Quality Denoising Dataset for Smartphone Cameras\n",
      "  The Perception-Distortion Tradeoff\n",
      "  Focus Manipulation Detection via Photometric Histogram Analysis\n",
      "  Image Blind Denoising With Generative Adversarial Network Based Noise Modeling\n",
      "  On the Duality Between Retinex and Image Dehazing\n",
      "  Image Super-Resolution via Dual-State Recurrent Networks\n",
      "  Deep Back-Projection Networks for Super-Resolution\n",
      "  Fast and Accurate Single Image Super-Resolution via Information Distillation Network\n",
      "  xUnit: Learning a Spatial Activation Function for Efficient Image Restoration\n",
      "  DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks\n",
      "  Universal Denoising Networks : A Novel CNN Architecture for Image Denoising\n",
      "  Learning a Discriminative Prior for Blind Image Deblurring\n",
      "  Single Image Dehazing via Conditional Generative Adversarial Network\n",
      "  Video Rain Streak Removal by Multiscale Convolutional Sparse Coding\n",
      "  A Hybrid l1-l0 Layer Decomposition Model for Tone Mapping\n",
      "  Hallucinated-IQA: No-Reference Image Quality Assessment via Adversarial Learning\n",
      "  Burst Denoising With Kernel Prediction Networks\n",
      "  Learning Deep Sketch Abstraction\n",
      "  Deeply Learned Filter Response Functions for Hyperspectral Reconstruction\n",
      "  Blind Predicting Similar Quality Map for Image Quality Assessment\n",
      "  Learning Dual Convolutional Neural Networks for Low-Level Vision\n",
      "  PieAPP: Perceptual Image-Error Assessment Through Pairwise Preference\n",
      "  Unsupervised Sparse Dirichlet-Net for Hyperspectral Image Super-Resolution\n",
      "  Gated Fusion Network for Single Image Dehazing\n",
      "  Classification-Driven Dynamic Image Enhancement\n",
      "  âZero-Shotâ Super-Resolution Using Deep Internal Learning\n",
      "  Learning to Sketch With Shortcut Cycle Consistency\n",
      "  Scale-Recurrent Network for Deep Image Deblurring\n",
      "  Deep Image Prior\n",
      "  Non-Blind Deblurring: Handling Kernel Uncertainty With CNNs\n",
      "  Separating Self-Expression and Visual Content in Hashtag Supervision\n",
      "  CRRN: Multi-Scale Guided Concurrent Reflection Removal Network\n",
      "  Recovering Realistic Texture in Image Super-Resolution by Deep Spatial Feature Transform\n",
      "  Fast End-to-End Trainable Guided Filter\n",
      "  SketchMate: Deep Hashing for Million-Scale Human Sketch Retrieval\n",
      "  Multi-Scale Weighted Nuclear Norm Image Restoration\n",
      "  Image Correction via Deep Reciprocating HDR Transformation\n",
      "  Image Restoration by Estimating Frequency Distribution of Local Patches\n",
      "  Crafting a Toolchain for Image Restoration by Deep Reinforcement Learning\n",
      "  Densely Connected Pyramid Dehazing Network\n",
      "  Density-Aware Single Image De-Raining Using a Multi-Stream Dense Network\n",
      "  Dynamic Scene Deblurring Using Spatially Variant Recurrent Neural Networks\n",
      "  ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing\n",
      "  Learning a Single Convolutional Super-Resolution Network for Multiple Degradations\n",
      "  Learning to Understand Image Blur\n",
      "  Nonlocal Low-Rank Tensor Factor Analysis for Image Restoration\n",
      "  Residual Dense Network for Image Super-Resolution\n",
      "  Single Image Reflection Separation With Perceptual Losses\n",
      "  The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\n",
      "  Defocus Blur Detection via Multi-Stream Bottom-Top-Bottom Fully Convolutional Network\n",
      "  Learning Rich Features for Image Manipulation Detection\n",
      "==============\n",
      "\n",
      "CLUSTER 12: Deep learning\n",
      "\n",
      "  A PID Controller Approach for Stochastic Optimization of Deep Networks\n",
      "  Teaching Categories to Human Learners With Visual Explanations\n",
      "  RoadTracer: Automatic Extraction of Road Networks From Aerial Images\n",
      "  The Power of Ensembles for Active Learning in Image Classification\n",
      "  Analytic Expressions for Probabilistic Moments of PL-DNN With Gaussian Input\n",
      "  Weakly Supervised Learning of Single-Cell Feature Embeddings\n",
      "  Scalable and Effective Deep CCA via Soft Decorrelation\n",
      "  Anatomical Priors in Convolutional Networks for Unsupervised Biomedical Segmentation\n",
      "  Structured Uncertainty Prediction Networks\n",
      "  Low-Shot Learning With Large-Scale Diffusion\n",
      "  Empirical Study of the Topology and Geometry of Deep Networks\n",
      "  Net2Vec: Quantifying and Explaining How Concepts Are Encoded by Filters in Deep Neural Networks\n",
      "  Lightweight Probabilistic Deep Networks\n",
      "  MoNet: Moments Embedding Network\n",
      "  Guided Proofreading of Automatic Segmentations for Connectomics\n",
      "  Geometric Robustness of Deep Networks: Analysis and Improvement\n",
      "  Sliced Wasserstein Distance for Learning Gaussian Mixture Models\n",
      "  A Deeper Look at Power Normalizations\n",
      "  Deep Learning Under Privileged Information Using Heteroscedastic Dropout\n",
      "  Discrete-Continuous ADMM for Transductive Inference in Higher-Order MRFs\n",
      "  CleanNet: Transfer Learning for Scalable Image Classifier Training With Label Noise\n",
      "  A Constrained Deep Neural Network for Ordinal Regression\n",
      "  Smooth Neighbors on Teacher Graphs for Semi-Supervised Learning\n",
      "  Wrapped Gaussian Process Regression on Riemannian Manifolds\n",
      "  Learning Deep Structured Active Contours End-to-End\n",
      "  Multi-Task Learning by Maximizing Statistical Dependence\n",
      "  Beyond the Pixel-Wise Loss for Topology-Aware Delineation\n",
      "  Improvements to Context Based Self-Supervised Learning\n",
      "  What Do Deep Networks Like to See?\n",
      "  Representing and Learning High Dimensional Data With the Optimal Transport Map From a Probabilistic Viewpoint\n",
      "  Stochastic Variational Inference With Gradient Linearization\n",
      "  Large-Scale Distance Metric Learning With Uncertainty\n",
      "  Geometry Aware Constrained Optimization Techniques for Deep Learning\n",
      "  Towards a Mathematical Understanding of the Difficulty in Learning With Feedforward Neural Networks\n",
      "  Joint Optimization Framework for Learning With Noisy Labels\n",
      "  Between-Class Learning for Image Classification\n",
      "  Learning Superpixels With Segmentation-Aware Affinity Loss\n",
      "  Lean Multiclass Crowdsourcing\n",
      "  Iterative Learning With Open-Set Noisy Labels\n",
      "  Learning a Discriminative Filter Bank Within a CNN for Fine-Grained Recognition\n",
      "  Unsupervised Feature Learning via Non-Parametric Instance Discrimination\n",
      "  Deep Texture Manifold for Ground Terrain Recognition\n",
      "  Robust Classification With Convolutional Prototype Learning\n",
      "  Multi-Cell Detection and Classification Using a Generative Convolutional Model\n",
      "  Missing Slice Recovery for Tensors Using a Low-Rank Model in Embedded Space\n",
      "  An Efficient and Provable Approach for Mixture Proportion Estimation Using Linear Independence Assumption\n",
      "  Multi-View Harmonized Bilinear Network for 3D Object Recognition\n",
      "  BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning\n",
      "  Deep Mutual Learning\n",
      "  Interpretable Convolutional Neural Networks\n",
      "  On the Importance of Label Quality for Semantic Segmentation\n",
      "==============\n",
      "\n",
      "CLUSTER 13: Temporal representation/prediction\n",
      "\n",
      "  When Will You Do What? - Anticipating Temporal Occurrences of Activities\n",
      "  Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments\n",
      "  LAMV: Learning to Align and Match Videos With Kernelized Temporal Layers\n",
      "  Excitation Backprop for RNNs\n",
      "  Rethinking the Faster R-CNN Architecture for Temporal Action Localization\n",
      "  Non-Linear Temporal Subspace Representations for Activity Recognition\n",
      "  Functional Map of the World\n",
      "  Learning to Act Properly: Predicting and Explaining Affordances From Images\n",
      "  Weakly-Supervised Action Segmentation With Iterative Soft Boundary Assignment\n",
      "  Who's Better? Who's Best? Pairwise Deep Ranking for Skill Determination\n",
      "  Who Let the Dogs Out? Modeling Dog Behavior From Visual Data\n",
      "  Demo2Vec: Reasoning Object Affordances From Online Videos\n",
      "  From Lifestyle Vlogs to Everyday Interactions\n",
      "  A Unifying Contrast Maximization Framework for Event Cameras, With Applications to Motion, Depth, and Optical Flow Estimation\n",
      "  Geometry Guided Convolutional Neural Networks for Self-Supervised Video Representation Learning\n",
      "  Actor and Action Video Segmentation From a Sentence\n",
      "  Detecting and Recognizing Human-Object Interactions\n",
      "  AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\n",
      "  Reinforcement Cutting-Agent Learning for Video Object Segmentation\n",
      "  Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\n",
      "  Finding \"It\": Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos\n",
      "  Learning to Look Around: Intelligently Exploring Unseen Environments for Unknown Tasks\n",
      "  Viewpoint-Aware Video Summarization\n",
      "  FFNet: Video Fast-Forwarding via Reinforcement Learning\n",
      "  A Memory Network Approach for Story-Based Temporal Summarization of 360Â° Videos\n",
      "  Temporal Deformable Residual Networks for Action Segmentation in Videos\n",
      "  A2-RL: Aesthetics Aware Reinforcement Learning for Image Cropping\n",
      "  Convolutional Sequence to Sequence Model for Human Dynamics\n",
      "  SSNet: Scale Selection Network for Online 3D Action Prediction\n",
      "  Event-Based Vision Meets Deep Learning on Steering Prediction for Self-Driving Cars\n",
      "  Weakly Supervised Action Localization by Sparse Temporal Pooling Network\n",
      "  Distort-and-Recover: Color Enhancement Using Deep Reinforcement Learning\n",
      "  Learning Latent Super-Events to Detect Multiple Activities in Videos\n",
      "  Egocentric Activity Recognition on a Budget\n",
      "  VirtualHome: Simulating Household Activities via Programs\n",
      "  Toward Driving Scene Understanding: A Dataset for Learning Driver Behavior and Causal Reasoning\n",
      "  Action Sets: Weakly Supervised Action Segmentation Without Ordering Constraints\n",
      "  NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning\n",
      "  Sim2Real Viewpoint Invariant Visual Servoing by Recurrent Control\n",
      "  Unsupervised Learning and Segmentation of Complex Activities From Video\n",
      "  HATS: Histograms of Averaged Time Surfaces for Robust Event-Based Object Classification\n",
      "  SeedNet: Automatic Seed Generation With Deep Reinforcement Learning for Robust Interactive Segmentation\n",
      "  Real-World Anomaly Detection in Surveillance Videos\n",
      "  Anticipating Traffic Accidents With Adaptive Loss and Large-Scale Incident DB\n",
      "  Coding Kendall's Shape Trajectories for 3D Action Recognition\n",
      "  Deep Progressive Reinforcement Learning for Skeleton-Based Action Recognition\n",
      "  A Closer Look at Spatiotemporal Convolutions for Action Recognition\n",
      "  Analysis of Hand Segmentation in the Wild\n",
      "  Object Referring in Videos With Language and Human Gaze\n",
      "  Appearance-and-Relation Networks for Video Classification\n",
      "  Pulling Actions out of Context: Explicit Separation for Effective Combination\n",
      "  Temporal Hallucinating for Action Recognition With Few Still Images\n",
      "  Video Representation Learning Using Discriminative Pooling\n",
      "  Gibson Env: Real-World Perception for Embodied Agents\n",
      "  Environment Upgrade Reinforcement Learning for Non-Differentiable Multi-Stage Pipelines\n",
      "  One-Shot Action Localization by Learning Sequence Matching Network\n",
      "  Multiple Granularity Group Interaction Prediction\n",
      "  MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\n",
      "  Now You Shake Me: Towards Automatic 4D Cinema\n",
      "  Towards Universal Representation for Unseen Action Recognition\n",
      "==============\n",
      "\n",
      "CLUSTER 17: Neural networks\n",
      "\n",
      "  Dense Decoder Shortcut Connections for Single-Pass Semantic Segmentation\n",
      "  In-Place Activated BatchNorm for Memory-Optimized Training of DNNs\n",
      "  Deep Cauchy Hashing for Hamming Space Retrieval\n",
      "  âLearning-Compressionâ Algorithms for Neural Net Pruning\n",
      "  Deep Hashing via Discrepancy Minimization\n",
      "  Dual Skipping Networks\n",
      "  Context Contrasted Feature and Gated Multi-Scale Aggregation for Scene Segmentation\n",
      "  Link and Code: Fast Indexing With Graphs and Compact Regression Codes\n",
      "  GraphBit: Bitwise Interaction Mining via Deep Reinforcement Learning\n",
      "  SYQ: Learning Symmetric Quantization for Efficient Deep Neural Networks\n",
      "  MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks\n",
      "  Hashing as Tie-Aware Learning to Rank\n",
      "  Squeeze-and-Excitation Networks\n",
      "  CondenseNet: An Efficient DenseNet Using Learned Group Convolutions\n",
      "  Decorrelated Batch Normalization\n",
      "  Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference\n",
      "  Learning a Complete Image Indexing Pipeline\n",
      "  Improved Lossy Image Compression With Priming and Spatially Adaptive Bit Rates for Recurrent Networks\n",
      "  Perturbative Neural Networks\n",
      "  NestedNet: Learning Nested Sparse Structures in Deep Neural Networks\n",
      "  Analyzing Filters Toward Efficient ConvNet\n",
      "  Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks\n",
      "  Learning Convolutional Networks for Content-Weighted Image Compression\n",
      "  Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization\n",
      "  Dynamic-Structured Semantic Propagation Network\n",
      "  Decoupled Networks\n",
      "  PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning\n",
      "  Conditional Probability Models for Deep Image Compression\n",
      "  Regularizing Deep Networks by Modeling and Predicting Label Structure\n",
      "  A Biresolution Spectral Framework for Product Quantization\n",
      "  HydraNets: Specialized Dynamic Architectures for Efficient Inference\n",
      "  Gesture Recognition: Focus on the Hands\n",
      "  Recurrent Residual Module for Fast Inference in Videos\n",
      "  SBNet: Sparse Blocks Network for Fast Inference\n",
      "  Detail-Preserving Pooling in Deep Networks\n",
      "  MobileNetV2: Inverted Residuals and Linear Bottlenecks\n",
      "  Deformation Aware Image Compression\n",
      "  Learning Compressible 360Â° Video Isomers\n",
      "  Feature Quantization for Defending Against Distortion of Images\n",
      "  Spatially-Adaptive Filter Units for Deep Neural Networks\n",
      "  CLIP-Q: Deep Network Compression Learning by In-Parallel Pruning-Quantization\n",
      "  Learning Time/Memory-Efficient Deep Architectures With Budgeted Super Networks\n",
      "  Feedback-Prop: Convolutional Neural Network Inference Under Partial Evidence\n",
      "  Non-Local Neural Networks\n",
      "  Two-Step Quantization for Low-Bit Neural Networks\n",
      "  Wide Compression: Tensor Ring Nets\n",
      "  Learning Steerable Filters for Rotation Equivariant CNNs\n",
      "  BlockDrop: Dynamic Inference Paths in Residual Networks\n",
      "  Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions\n",
      "  Interleaved Structured Sparse Convolutional Neural Networks\n",
      "  Quantization of Fully Convolutional Networks for Accurate Biomedical Image Segmentation\n",
      "  Convolutional Neural Networks With Alternately Updated Clique\n",
      "  DenseASPP for Semantic Segmentation in Street Scenes\n",
      "  Deep Layer Aggregation\n",
      "  Learning Strict Identity Mappings in Deep Residual Networks\n",
      "  NISP: Pruning Networks Using Neuron Importance Score Propagation\n",
      "  ClcNet: Improving the Efficiency of Convolutional Neural Network Using Channel Local Convolutions\n",
      "  Efficient Large-Scale Approximate Nearest Neighbor Search on OpenCL FPGA\n",
      "  ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\n",
      "  Practical Block-Wise Neural Network Architecture Generation\n",
      "  Towards Effective Low-Bitwidth Convolutional Neural Networks\n",
      "  Learning Transferable Architectures for Scalable Image Recognition\n",
      "==============\n",
      "\n",
      "CLUSTER 3: Object localisation/detection\n",
      "\n",
      "  Efficient Interactive Annotation of Segmentation Datasets With Polygon-RNN++\n",
      "  Learning Pixel-Level Semantic Affinity With Image-Level Supervision for Weakly Supervised Semantic Segmentation\n",
      "  The LovÃ¡sz-Softmax Loss: A Tractable Surrogate for the Optimization of the Intersection-Over-Union Measure in Neural Networks\n",
      "  COCO-Stuff: Thing and Stuff Classes in Context\n",
      "  Cascade R-CNN: Delving Into High Quality Object Detection\n",
      "  Iterative Visual Reasoning Beyond Convolutions\n",
      "  MaskLab: Instance Segmentation by Refining Object Detection With Semantic and Direction Features\n",
      "  SeGAN: Segmenting and Generating the Invisible\n",
      "  Dynamic Zoom-In Network for Fast Object Detection in Large Images\n",
      "  Multi-Evidence Filtering and Fusion for Multi-Label Classification, Object Detection and Semantic Segmentation Based on Weakly Supervised Learning\n",
      "  Objects as Context for Detecting Their Semantic Parts\n",
      "  Hierarchical Recurrent Attention Networks for Structured Online Maps\n",
      "  Learning to Segment Every Thing\n",
      "  Relation Networks for Object Detection\n",
      "  Weakly-Supervised Semantic Segmentation Network With Deep Seeded Region Growing\n",
      "  Tensorize, Factorize and Regularize: Robust Visual Relationship Learning\n",
      "  Image Generation From Scene Graphs\n",
      "  Dynamic Graph Generation Network: Generating Relational Knowledge From Diagrams\n",
      "  Recurrent Pixel Embedding for Instance Grouping\n",
      "  Learning Intelligent Dialogs for Bounding Box Annotation\n",
      "  Interactive Image Segmentation With Latent Diversity\n",
      "  Thoracic Disease Identification and Localization With Limited Supervision\n",
      "  Path Aggregation Network for Instance Segmentation\n",
      "  Structure Inference Net: Object Detection Using Scene-Level Context and Instance-Level Relationships\n",
      "  Beyond Holistic Object Recognition: Enriching Image Understanding With Part States\n",
      "  Deep Extreme Cut: From Extreme Points to Object Segmentation\n",
      "  Efficient Optimization for Rank-Based Loss Functions\n",
      "  Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors\n",
      "  Boosting Self-Supervised Learning via Knowledge Transfer\n",
      "  MegDet: A Large Mini-Batch Object Detector\n",
      "  Deep Reinforcement Learning of Region Proposal Networks for Object Detection\n",
      "  Data Distillation: Towards Omni-Supervised Learning\n",
      "  Learning Globally Optimized Object Detector via Policy Gradient\n",
      "  Bootstrapping the Performance of Webly Supervised Semantic Segmentation\n",
      "  Generative Adversarial Learning Towards Fast Weakly Supervised Detection\n",
      "  An Analysis of Scale Invariance in Object Detection Â­ SNIP\n",
      "  R-FCN-3000 at 30fps: Decoupling Detection and Classification\n",
      "  Normalized Cut Loss for Weakly-Supervised CNN Segmentation\n",
      "  Improving Object Localization With Fitness NMS and Bounded IoU Loss\n",
      "  Revisiting Knowledge Transfer for Training Object Class Detectors\n",
      "  The INaturalist Species Classification and Detection Dataset\n",
      "  Min-Entropy Latent Model for Weakly Supervised Object Detection\n",
      "  Multi-Scale Location-Aware Kernel Representation for Object Detection\n",
      "  Repulsion Loss: Detecting Pedestrians in a Crowd\n",
      "  Towards Human-Machine Cooperation: Self-Supervised Sample Mining for Object Detection\n",
      "  Good View Hunting: Learning Photo Composition From Dense View Pairs\n",
      "  Revisiting Dilated Convolution: A Simple Approach for Weakly- and Semi-Supervised Semantic Segmentation\n",
      "  DOTA: A Large-Scale Dataset for Object Detection in Aerial Images\n",
      "  Weakly Supervised Coupled Networks for Visual Sentiment Analysis\n",
      "  Learning a Discriminative Feature Network for Semantic Segmentation\n",
      "  Recurrent Saliency Transformation Network: Incorporating Multi-Stage Visual Cues for Small Organ Segmentation\n",
      "  Neural Motifs: Scene Graph Parsing With Global Context\n",
      "  Feature Selective Networks for Object Detection\n",
      "  Adversarial Complementary Learning for Weakly Supervised Object Localization\n",
      "  Context Encoding for Semantic Segmentation\n",
      "  DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection Under Partial Occlusion\n",
      "  Single-Shot Object Detection With Enriched Semantics\n",
      "  Single-Shot Refinement Neural Network for Object Detection\n",
      "  W2F: A Weakly-Supervised to Fully-Supervised Framework for Object Detection\n",
      "  Zigzag Learning for Weakly Supervised Object Detection\n",
      "  Pseudo Mask Augmented Object Detection\n",
      "  Scale-Transferrable Object Detection\n",
      "  Weakly Supervised Instance Segmentation Using Class Peak Response\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in cluster_size.index.values.tolist():\n",
    "    print('CLUSTER ' + str(c) + ': ' + cluster_labels[c] + '\\n')\n",
    "    df_c = df[df.cluster == c]\n",
    "    for name in df_c.name:\n",
    "        print('  ' + name)\n",
    "    print('==============\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this set of notebooks I created a paper segmentation pipeline based on NLP to split the papers published at the CVPR 2018 conference into topics. Labelling each cluster (i.e. assigning topic labels to clusters) was done manually after visually inspecting the title of the papers in each cluster. These labels try to identify the predominant topic in each cluster, but given the nature of the K-means algorithm, it may happen that some clusters contain some papers that do not seem to fit very well with the overall cluster topic. One reason for this may be the existence of papers which are focused on general topics rather than specific applications, but being driven into an specific cluster due to the examples provided in the paper. \n",
    "\n",
    "Additionally, and also due to the nature of K-means algorithm, we may encounter some topics that are split accross more than one cluster, like 3D reconstruction (clusters 20 and 2), face detection/recognition (clusters 6 and 22), or GANs (25, 10).\n",
    "\n",
    "I felt more confident labelling some clusters than others. Generally, I would feel more confident labelling the smallest clusters, so these labels have to be taken with a pinch of salt. One way of improving the work presented here could be by analysing the proportion of papers in each cluster that genuilly match the cluster label. \n",
    "\n",
    "Finally, I'd like to add that I started this analysis because I was interested in finding out what were the main current topics in the Computer Vision field after many years working on other unrelated topics. The fact that CVPR 2018, the most important Computer Vision Conference, made the published papers openly available on the Internet seemed like a very good opportunity to perform this task. If I was still part of Academia, I would use this work as a first step towards identifying the papers I could be interested in from the total amount of about 1000 papers published in the conference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
